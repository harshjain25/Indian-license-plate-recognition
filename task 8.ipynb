{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ignored-familiar",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "major-retirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "#detecting license plate on the vehicle\n",
    "plateCascade = cv2.CascadeClassifier('indian_license_plate.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "#detect the plate and return car + plate image\n",
    "def plate_detect(img):\n",
    "    plateImg = img.copy()\n",
    "    roi = img.copy()\n",
    "    plateRect = plateCascade.detectMultiScale(plateImg,scaleFactor = 1.2, minNeighbors = 7)\n",
    "    for (x,y,w,h) in plateRect:\n",
    "        roi_ = roi[y:y+h, x:x+w, :]\n",
    "        plate_part = roi[y:y+h, x:x+w, :]\n",
    "        cv2.rectangle(plateImg,(x+2,y),(x+w-3, y+h-5),(0,255,0),3)\n",
    "    return plateImg, plate_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-benefit",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normal function to display \n",
    "def display_img(img):\n",
    "    img_ = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img_)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-quantum",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test image is used for detecting plate\n",
    "inputImg = cv2.imread('car.jpg')\n",
    "inpImg, plate = plate_detect(inputImg)\n",
    "display_img(inpImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-crystal",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_img(plate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-dress",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_contours(dimensions, img) :\n",
    "\n",
    "    #finding all contours in the image using \n",
    "    #retrieval mode: RETR_TREE\n",
    "    #contour approximation method: CHAIN_APPROX_SIMPLE\n",
    "    cntrs, _ = cv2.findContours(img.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    #Approx dimensions of the contours\n",
    "    lower_width = dimensions[0]\n",
    "    upper_width = dimensions[1]\n",
    "    lower_height = dimensions[2]\n",
    "    upper_height = dimensions[3]\n",
    "    \n",
    "    #Check largest 15 contours for license plate character respectively\n",
    "    cntrs = sorted(cntrs, key=cv2.contourArea, reverse=True)[:15]\n",
    "    \n",
    "    ci = cv2.imread('contour.jpg')\n",
    "    \n",
    "    x_cntr_list = []\n",
    "    target_contours = []\n",
    "    img_res = []\n",
    "    for cntr in cntrs :\n",
    "        #detecting contour in binary image and returns the coordinates of rectangle enclosing it\n",
    "        intX, intY, intWidth, intHeight = cv2.boundingRect(cntr)\n",
    "        \n",
    "        #checking the dimensions of the contour to filter out the characters by contour's size\n",
    "        if intWidth > lower_width and intWidth < upper_width and intHeight > lower_height and intHeight < upper_height :\n",
    "            x_cntr_list.append(intX) \n",
    "            char_copy = np.zeros((44,24))\n",
    "            #extracting each character using the enclosing rectangle's coordinates.\n",
    "            char = img[intY:intY+intHeight, intX:intX+intWidth]\n",
    "            char = cv2.resize(char, (20, 40))\n",
    "            cv2.rectangle(ci, (intX,intY), (intWidth+intX, intY+intHeight), (50,21,200), 2)\n",
    "            plt.imshow(ci, cmap='gray')\n",
    "            char = cv2.subtract(255, char)\n",
    "            char_copy[2:42, 2:22] = char\n",
    "            char_copy[0:2, :] = 0\n",
    "            char_copy[:, 0:2] = 0\n",
    "            char_copy[42:44, :] = 0\n",
    "            char_copy[:, 22:24] = 0\n",
    "            img_res.append(char_copy) # List that stores the character's binary image (unsorted)\n",
    "            \n",
    "    #return characters on ascending order with respect to the x-coordinate\n",
    "            \n",
    "    plt.show()\n",
    "    #arbitrary function that stores sorted list of character indeces\n",
    "    indices = sorted(range(len(x_cntr_list)), key=lambda k: x_cntr_list[k])\n",
    "    img_res_copy = []\n",
    "    for idx in indices:\n",
    "        img_res_copy.append(img_res[idx])# stores character images according to their index\n",
    "    img_res = np.array(img_res_copy)\n",
    "\n",
    "    return img_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-lyric",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_characters(image) :\n",
    "\n",
    "    #pre-processing cropped image of plate\n",
    "    #threshold: convert to pure b&w with sharpe edges\n",
    "    #erod: increasing the backgroung black\n",
    "    #dilate: increasing the char white\n",
    "    img_lp = cv2.resize(image, (333, 75))\n",
    "    img_gray_lp = cv2.cvtColor(img_lp, cv2.COLOR_BGR2GRAY)\n",
    "    _, img_binary_lp = cv2.threshold(img_gray_lp, 200, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    img_binary_lp = cv2.erode(img_binary_lp, (3,3))\n",
    "    img_binary_lp = cv2.dilate(img_binary_lp, (3,3))\n",
    "\n",
    "    LP_WIDTH = img_binary_lp.shape[0]\n",
    "    LP_HEIGHT = img_binary_lp.shape[1]\n",
    "    img_binary_lp[0:3,:] = 255\n",
    "    img_binary_lp[:,0:3] = 255\n",
    "    img_binary_lp[72:75,:] = 255\n",
    "    img_binary_lp[:,330:333] = 255\n",
    "\n",
    "    #estimations of character contours sizes of cropped license plates\n",
    "    dimensions = [LP_WIDTH/6,\n",
    "                       LP_WIDTH/2,\n",
    "                       LP_HEIGHT/10,\n",
    "                       2*LP_HEIGHT/3]\n",
    "    plt.imshow(img_binary_lp, cmap='gray')\n",
    "    plt.show()\n",
    "    cv2.imwrite('contour.jpg',img_binary_lp)\n",
    "\n",
    "    #getting contours\n",
    "    char_list = find_contours(dimensions, img_binary_lp)\n",
    "\n",
    "    return char_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-community",
   "metadata": {},
   "outputs": [],
   "source": [
    "char = segment_characters(plate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-athletics",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(char[i], cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-mining",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score \n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Flatten, MaxPooling2D, Dropout, Conv2D\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, width_shift_range=0.1, height_shift_range=0.1)\n",
    "path = 'data/data/'\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        path+'/train',  \n",
    "        target_size=(28,28), \n",
    "        batch_size=1,\n",
    "        class_mode='sparse')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "        path+'/val',  \n",
    "        target_size=(28,28),  \n",
    "        class_mode='sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-flooring",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It is the harmonic mean of precision and recall\n",
    "#Output range is [0, 1]\n",
    "#Works for both multi-class and multi-label classification\n",
    "def f1score(y, y_pred):\n",
    "    return f1_score(y, tf.math.argmax(y_pred, axis=1), average='micro') \n",
    "\n",
    "def custom_f1score(y, y_pred):\n",
    "    return tf.py_function(f1score, (y, y_pred), tf.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-spelling",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, (22,22), input_shape=(28, 28, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(32, (16,16), input_shape=(28, 28, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, (8,8), input_shape=(28, 28, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, (4,4), input_shape=(28, 28, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(36, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizers.Adam(lr=0.0001), metrics=[custom_f1score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-exchange",
   "metadata": {},
   "outputs": [],
   "source": [
    "class stop_training_callback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('val_custom_f1score') > 0.99):\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-wellington",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "callbacks = [stop_training_callback()]\n",
    "model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch = train_generator.samples // batch_size,\n",
    "      validation_data = validation_generator, \n",
    "      epochs = 80, verbose=1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-girlfriend",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_dimension(img):\n",
    "    new_img = np.zeros((28,28,3))\n",
    "    for i in range(3):\n",
    "        new_img[:,:,i] = img\n",
    "    return new_img\n",
    "  \n",
    "def show_results():\n",
    "    dic = {}\n",
    "    characters = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "    for i,c in enumerate(characters):\n",
    "        dic[i] = c\n",
    "\n",
    "    output = []\n",
    "    for i,ch in enumerate(char): \n",
    "        img_ = cv2.resize(ch, (28,28), interpolation=cv2.INTER_AREA)\n",
    "        img = fix_dimension(img_)\n",
    "        img = img.reshape(1,28,28,3)\n",
    "        y_ = model.predict_classes(img)[0]\n",
    "        character = dic[y_] #\n",
    "        output.append(character) \n",
    "        \n",
    "    plate_number = ''.join(output)\n",
    "    \n",
    "    return plate_number\n",
    "\n",
    "final_plate = show_results()\n",
    "print(final_plate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-nevada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import xmltodict\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-shanghai",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vehicle_info(plate_number):\n",
    "    r = requests.get(\"http://www.regcheck.org.uk/api/reg.asmx/CheckIndia?RegistrationNumber={0}&username=geerling\".format(str(plate_number)))\n",
    "    data = xmltodict.parse(r.content)\n",
    "    jdata = json.dumps(data)\n",
    "    df = json.loads(jdata)\n",
    "    df1 = json.loads(df['Vehicle']['vehicleJson'])\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-provider",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_vehicle_info(final_plate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-factory",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('license_plate_character.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-house",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_vehicle_info('WB06F5977')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
